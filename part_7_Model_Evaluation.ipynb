{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7HRrvACuOxR4bLYtKKBpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ron-levi1/Social-Media-Advertisement-Performance/blob/main/part_7_Model_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZbGCChj_MjZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04371059-6259-46a0-bc27-89a6ffbdcf58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import warnings; warnings.filterwarnings(\"ignore\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import joblib\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_recall_fscore_support,\n",
        "    f1_score, roc_auc_score, log_loss, confusion_matrix, classification_report\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load the best tuned XGB model (saved after Fine-Tuning) and the DEV/TEST splits from Drive. DEV will be used to tune the decision threshold; TEST is held out for the final performance report."
      ],
      "metadata": {
        "id": "sRNeN00BsjqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "est_model = joblib.load('/content/drive/MyDrive/xgb_best_model.pkl')\n",
        "best_model = est_model\n",
        "\n",
        "X_dev = pd.read_csv('/content/drive/MyDrive/X_dev.csv')\n",
        "y_dev = pd.read_csv('/content/drive/MyDrive/y_dev.csv')\n",
        "X_test = pd.read_csv('/content/drive/MyDrive/X_test.csv')\n",
        "y_test = pd.read_csv('/content/drive/MyDrive/y_test.csv')\n",
        "\n",
        "y_dev = y_dev.squeeze()\n",
        "y_test = y_test.squeeze()"
      ],
      "metadata": {
        "id": "ZXZGbi4cruHp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use probabilities (predict_proba) to search thresholds between 0.05â€“0.95 and pick the value that maximizes F1 on DEV. This avoids the default 0.5 cutoff, which can be sub-optimal with imbalanced data."
      ],
      "metadata": {
        "id": "7e0PLsvMsnkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proba_dev = best_model.predict_proba(X_dev)[:, 1]\n",
        "ths = np.linspace(0.05, 0.95, 91)\n",
        "\n",
        "best_th, best_f1 = 0.5, -1\n",
        "for t in ths:\n",
        "    y_hat = (proba_dev >= t).astype(int)\n",
        "    f1 = f1_score(y_dev, y_hat)\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_th = f1, t\n",
        "\n",
        "print(f\"Chosen threshold on DEV: {best_th:.3f} (DEV F1={best_f1:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "J2qq_MZbrwWC",
        "outputId": "04ab1a5b-acc5-45e2-9f4a-3fa65651dbe4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chosen threshold on DEV: 0.050 (DEV F1=0.252)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Apply the chosen threshold to TEST predictions and compute Accuracy, Precision, Recall, F1 on labels, ROC-AUC on probabilities, and Log-loss. Print the confusion matrix and a classification report to summarize performance on truly unseen data."
      ],
      "metadata": {
        "id": "wwUpv2HXsvhk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proba_test = best_model.predict_proba(X_test)[:, 1]\n",
        "y_test_pred = (proba_test >= best_th).astype(int)\n",
        "\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_test_pred, average='binary', zero_division=0)\n",
        "acc = accuracy_score(y_test, y_test_pred)\n",
        "auc_prob = roc_auc_score(y_test, proba_test)\n",
        "ll = log_loss(y_test, np.vstack([1 - proba_test, proba_test]).T)\n",
        "cm = confusion_matrix(y_test, y_test_pred)\n",
        "\n",
        "print(\"\\n=== TEST Metrics (thresholded) ===\")\n",
        "print(f\"Accuracy:  {acc:.4f}\")\n",
        "print(f\"Precision: {prec:.4f}\")\n",
        "print(f\"Recall:    {rec:.4f}\")\n",
        "print(f\"F1-score:  {f1:.4f}\")\n",
        "print(f\"ROC-AUC:   {auc_prob:.4f}\")\n",
        "print(f\"Log-loss:  {ll:.4f}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix (TEST):\")\n",
        "print(cm)\n",
        "\n",
        "print(\"\\nClassification Report (TEST):\")\n",
        "print(classification_report(y_test, y_test_pred, zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MUj1Tb5dr0ey",
        "outputId": "36f58348-1bad-4ea6-bd57-25b27b46497f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== TEST Metrics (thresholded) ===\n",
            "Accuracy:  0.2977\n",
            "Precision: 0.1506\n",
            "Recall:    0.7901\n",
            "F1-score:  0.2529\n",
            "ROC-AUC:   0.5020\n",
            "Log-loss:  0.5416\n",
            "\n",
            "Confusion Matrix (TEST):\n",
            "[[10728 40244]\n",
            " [ 1895  7133]]\n",
            "\n",
            "Classification Report (TEST):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.21      0.34     50972\n",
            "           1       0.15      0.79      0.25      9028\n",
            "\n",
            "    accuracy                           0.30     60000\n",
            "   macro avg       0.50      0.50      0.30     60000\n",
            "weighted avg       0.74      0.30      0.32     60000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### The final XGBoost model achieved a recall of 0.79 on the test set, meaning it successfully identified most positive engagement events. However, precision dropped to 0.15, indicating a high number of false positives. The overall F1-score (0.25) and ROC-AUC (0.50) suggest that while the model captures many positives, it lacks discriminative power and generalization. The low optimal threshold (0.05) confirms a strong imbalance in the data and potential overfitting to the oversampled training distribution."
      ],
      "metadata": {
        "id": "mn5tKuDF5738"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Store the selected DEV threshold and all final TEST metrics in a CSV on Drive so they can be referenced in your report or reused later."
      ],
      "metadata": {
        "id": "DqMnjoa-syV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_results = {\n",
        "    \"Threshold_DEV\": best_th,\n",
        "    \"Accuracy_TEST\": acc,\n",
        "    \"Precision_TEST\": prec,\n",
        "    \"Recall_TEST\": rec,\n",
        "    \"F1_TEST\": f1,\n",
        "    \"AUC_prob_TEST\": auc_prob,\n",
        "    \"LogLoss_TEST\": ll\n",
        "}\n",
        "\n",
        "pd.DataFrame([final_results]).to_csv('/content/drive/MyDrive/final_xgb_results.csv', index=False)\n",
        "print(\"\\n Final metrics saved to Drive: final_xgb_results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f6Cto4Wer3vE",
        "outputId": "fc2401c2-874e-4b0e-c5fa-c62aec5bd984"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Final metrics saved to Drive: final_xgb_results.csv\n"
          ]
        }
      ]
    }
  ]
}